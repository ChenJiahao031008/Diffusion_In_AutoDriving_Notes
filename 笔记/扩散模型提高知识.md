# 扩散模型提高知识

[TOC]

------------------

## Diffusion Transformer（DiT）

### 1. 关键点分析

1. **转成Transform**：同样使用 VAE, 并对不同的 patch 赋予 token （patch 2/4/8）

### 2. Norm layer 归一化知识点汇总

1. **标准公式如下**

$$
y = \frac{x - E[x]}{\sqrt{Var[x] + \epsilon}} + r + \beta
$$

2. **对于 BN 和 LN**
   - **BN**: 对 (B,N,D) 中 D 维归一化
   - **LN**: 对 (B,N,D) 中 B 维归一化
     - PostNorm: 性能更好，但是更难优化（残差随层数呈指数增加，容易梯度消失或爆炸）
     - PreNorm: 网络结构简单，性能较差（保留更多残差信息），因此PreNorm更优效果，更常用。

3. **对于Adapt-Zero Norm**

   + **Norm layer**：γ、β为可学习参数，在训练中学习但固定应用于所有输入  
   + **Adapt Norm layer**   
     1.  基于条件信息动态生成：$γ, β = $MLP(condition)   
     2. 通过通道注意力自适应生成：$γ, β = f(x)$  
     3. 本文中Adaptive 条件嵌入：时间步嵌入与类别嵌入被融合为条件向量

   + **Adapt-Zero Norm**： $\gamma =1,\ \beta=0$，使初始化阶段模型接近标准归一化。本文中额外学习一个逐channel的参数$\alpha$（门控参数，残差初始贡献为0） 

### 2. 三种 DiT Block 设计

1. 条件和图像直接相加
2. 使用 cross-attention
3. 加入 adapt Norm layer 层（3.1 不同网络添加位置）->  效果最好（3.2 使用全零初始化）

<img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250329220318589.png" alt="image-20250329220318589" style="zoom:80%;" />

## Low Rank Adaptation (LoRA)

https://arxiv.org/pdf/2106.09685

###  1. LoRA的出现的原因

+ 使用LORA，训练参数仅为整体参数的万分之一、GPU显存使用量减少2/3且不会引入额外的推理耗时

### 2. 低秩假设：LoRA的理论基础

**预训练模型拥有极小的内在维度(instrisic dimension)，即存在一个极低维度的参数，微调它和在全参数空间中微调能起到相同的效果**。具体而言：

1. **权重更新的低秩特性**：矩阵秩表示其线性无关的行或列的数量。研究发现，微调过程中权重的变化ΔW可以用远低于其原始维度的向量组合表示。
2. **内在维度**：在预训练后，越大的模型有越小的内在维度，这也解释了为何大模型都拥有很好的few-shot能力。

### 3. LoRA微调

![image-20250323165613779](%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250323165613779.png)

公式： $h = W_0x+ \Delta Wx = W_0x + \frac{\alpha}{r}\cdot B Ax$。

+ 其中 $W_0 \in \R ^{(d\times r)}$ 是预训练的权重矩阵，$\Delta W = BA$ 就是我们添加的额外矩阵，$B \in \R ^ {(d \times r)}, A \in \R^{r\times k}$，$r \ll \min(d,k)$ 表示矩阵的秩，为超参。

+ 初始化时，矩阵 A 随机高斯初始化$N(0, \sigma^2)$初始化，其中$\sigma = 1/\sqrt{r}$，矩阵 B 初始化为0：在初始阶段这两个矩阵相乘为0，可以保证在初始阶段时，只有左边的主干生效。然后 BA 还会乘以一个缩放因子 $\frac{\alpha}{r}$ ，α也是超参。
+ 训练的时候，预训练的权重矩阵全部都是冻结的，仅训练A和B中的参数。

### 4. Lora 实现细节

1. **参数合并机制** ：LoRA不会增加额外的推理时间成本

   + **微调后合并权重** ：在LoRA训练完成后，通常会将低秩增量矩阵（ΔW）直接合并到原始模型的权重矩阵（W）中，形成新的权重矩阵 W′=W+ΔW。**推理时直接使用合并后的权重**，无需额外计算步骤，因此计算复杂度与原始模型完全一致。

2. LoRA版本的全连接层：

   ```python
   # 在调用凯明初始化的时候注释里写的高斯分布，调用的却是均匀分布，而且参数a的值设置的是根号5，但a表示的是leaky relu的负斜率系数，一般是0.01这样的小值，不可能超过1
   def reset_parameters(self):
       nn.Linear.reset_parameters(self)
       if hasattr(self, 'lora_A'):
           # initialize A the same way as the default for nn.Linear and B to zero
           nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))
           nn.init.zeros_(self.lora_B)
           
   def forward(self, x: torch.Tensor):
       def T(w):
           return w.transpose(0, 1) if self.fan_in_fan_out else w
       if self.r > 0 and not self.merged:
           result = F.linear(x, T(self.weight), bias=self.bias)            
           result += (self.lora_dropout(x) @ self.lora_A.transpose(0, 1) @ self.lora_B.transpose(0, 1)) * self.scaling
           return result
       else:
           return F.linear(x, T(self.weight), bias=self.bias)
   ```

3. LoRA版本的卷积层：

   将增量 $\Delta W \in \mathbb{R}^{C_{\text{out}} \times C_{\text{in}} \times K_h \times K_w}$ 分解为两个低秩矩阵：
   - $$ A \in \mathbb{R}^{C_{\text{out}} \times r \times 1 \times 1} $$（逐点卷积，调整通道维度）
   - $$ B \in \mathbb{R}^{r \times C_{\text{in}} \times K_h \times K_w} $$（低秩卷积核，捕捉空间特征）  

   ```python
    ## CASE 1: https://blog.csdn.net/weixin_54338498/article/details/136811439
       if isinstance(module, nn.Conv2d):
           assert len(self._up_weight.shape) == len(self._down_weight.shape) == 4
   
           r = self._r
           in_dim = module.in_channels
           out_dim = module.out_channels
           kernel = module.kernel_size
           stride = module.stride
           padding = module.padding
   
           self._lora_down = nn.Conv2d(in_dim, r, kernel, stride, padding, bias=False)
           self._lora_up = nn.Conv2d(r, out_dim, (1, 1), (1, 1), bias=False)
   
       self._lora_down.weight = nn.Parameter(self._down_weight)
       self._lora_up.weight = nn.Parameter(self._up_weight)
       
    ## CASE 2: https://zhuanlan.zhihu.com/p/658007966
    ##         https://github.com/microsoft/LoRA/blob/main/loralib/layers.py
   	def __init__(....):
           self.lora_A = nn.Parameter(
               self.conv.weight.new_zeros((r * kernel_size, in_channels * kernel_size))
           )
           self.lora_B = nn.Parameter(
             self.conv.weight.new_zeros((
                 out_channels//self.conv.groups * kernel_size, r * kernel_size))
           )
           self.scaling = self.lora_alpha / self.r
       
       def train(self, mode=True):
   		...
           self.conv.weight.data += 
               (self.lora_B @ self.lora_A).view(self.conv.weight.shape) * self.scaling
       	self.merged = True
   
       def forward(self, x):
           if self.r > 0 and not self.merged:
               return self.conv._conv_forward(
                   x, 
                   self.conv.weight + 
                   	(self.lora_B @ self.lora_A).view(
                           self.conv.weight.shape) * self.scaling,
                   self.conv.bias
               )
           return self.conv(x)
   
   class Conv2d(ConvLoRA):
       def __init__(self, *args, **kwargs):
           super(Conv2d, self).__init__(nn.Conv2d, *args, **kwargs)
   ```

4. LoRA版本的Transform：

   ![image-20250323184202390](%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250323184202390.png)

   从上图我们可以看到：将所有微调参数都放到attention的某一个参数矩阵的效果并不好，将可微调参数平均分配到Wq和Wk的效果最好

   ```python
   ## using lora in transform. for example q,v 
   # ===== Before =====
   # qkv_proj = nn.Linear(d_model, 3*d_model)
   # ===== After =====
   # Break it up (remember to modify the pretrained checkpoint accordingly)
   q_proj = lora.Linear(d_model, d_model, r=8)
   k_proj = nn.Linear(d_model, d_model)
   v_proj = lora.Linear(d_model, d_model, r=8)
   # Alternatively, use lora.MergedLinear (recommended)
   qkv_proj = lora.MergedLinear(d_model, 3*d_model, r=8, enable_lora=[True, False, True])
   
   ## 具体实现详见代码：https://github.com/microsoft/LoRA/blob/main/loralib/layers.py
   ```

### 5. 内存优化与计算效率分析

|                    | 原始权重                       | **LoRA权重**                         | 参数比例                                                     |
| ------------------ | ------------------------------ | ------------------------------------ | ------------------------------------------------------------ |
| 参数存储           | $d \times k$ 个参数            | $r \times (d + k)$ 个参数            | $\frac{r \times (d + k)}{d \times k} \approx r \times \left(\frac{1}{k} + \frac{1}{d}\right)$ |
| 优化器状态（Adam） | $2 \times d \times k$ 个浮点数 | $2 \times r \times (d + k)$ 个浮点数 | 内存减少：约99.6%                                            |
| 梯度计算与反向传播 | $d \times k$ 个梯度            | $r \times (d + k)$ 个梯度            |                                                              |

### 6. 训练/超参细节

1. **学习率调整**：LoRA通常需要比全参数微调更高的学习率，推荐范围：[5e-4, 1e-3]，是全参数微调学习率的5-10倍

2. **权重衰减处理**：对LoRA权重应用较小的权重衰减，典型值：0.01-0.1之间

3. **秩参数(r)选择**：

   + 原始论文表明，在大多数NLP任务上，r=8足够有效（简单任务，r=4~8）
   + 对于更复杂任务，r=16或r=32可能更合适（生成任务：r=16~32）

4.  **缩放因子α更新**：

   + 常见设置策略：
     + 设置α=r：使缩放因子α/r=1，保持原始更新幅度
     + 设置α=2r：略微增强LoRA更新的影响
     + α的范围通常在[1, 32]之间

   + 与学习率的关系：

     + α与学习率有相乘效应

     + 增大α等效于增加LoRA参数的有效学习率

------------

## ControlNet

### 1. 基本组件

ControlNet首先将原来的模型锁定，称之为locked copy，其中“锁定”副本中的权重保持不变，保留了Stable Diffusion模型原本的能力；与此同时，使用额外数据对“可训练”副本（称之为trainable copy）进行微调，学习我们想要添加的条件，并同时在输入和输出的部分，加上两层卷积。但是不同的是，这两个卷积是**初始化为零的 1×1 卷积层**。

<img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250329203152255.png" alt="image-20250329203152255" style="zoom: 80%;" />

公式表述为：

<img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250329224118836.png" alt="image-20250329224118836" style="zoom: 67%;" />

### 2. 基本架构

<img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250329203343429.png" alt="image-20250329203343429" style="zoom: 67%;" />

1. **将图像空间Condition转化为隐空间Condition**：训练过程中添加了四层卷积层，这些卷积层的卷积核为4×4，步长为2，通道分别为16，32，64，128，初始化为高斯权重，并与整个ControlNet模型进行联合训练。

2. **当prompt对于SD模型不可见时，编码器倾向于从条件输入中学习更多语义，以替代prompt**：研究者随机将 50% 的文本 prompts \( $c_*t$ \) 替换为空字符串，这有利于 ControlNet 从输入条件（例如 Canny 边缘图或人类涂鸦等）中识别语义内容的能力。

3. **Classifier-free guidance resolution weighting推理** ：
   $$
   \epsilon_{prd} = \epsilon_{uc} + \beta_{cfg} (\epsilon_c - \epsilon_{uc})
   $$
   在上面的式子中，$\epsilon_{prd}$ 代表模型最终的输出，$\epsilon_{uc}$ 代表模型 unconditional output（可以理解为普通 stable diffusion 的结果），$\epsilon_c$ 表示模型 conditional output，$\beta_{cfg}$ 是用户可调整的超参数。

   但是这样还存在一个问题：假设存在一个 Canny 处理后的图像，输入进网络作为 condition 之后，可能会完全去除 CFG 的指导，但是如果只用 condition，可能又会让指导过于强烈。

   解决方案是将条件图像先给到 $\epsilon_c$ 当中，然后根据每个块的分辨率，将每个连接在 Stable Diffusion 和 controlNet 乘以一个系数 $w_i=64/h_i$，其中 $h_i$ 是第 i 个特征块的大小，通过逐渐降低 CFG 指导的强度，可以得到较好的效果。

### 3. 关键点剖析

+ **如果zero convolution模块的初始权重为零，那么梯度也为零，ControlNet模型将不会学到任何东西。那么为什么“zero convolution模块”有效呢？**

  假设ControlNet的权重为：$y=wx+b$ ，可以得到对应的梯度求导：
  $$
  \partial y/ \partial w=x, \partial y/\partial x=w, \partial y/\partial b=1
  $$
  

  如果此时 $w=0$ 并且$x\neq0$, 可以得到:
  $$
  \partial y / \partial w\neq0 , \partial y /\partial x =0 , \partial y / \partial b \neq0
  $$
  这就意味着只要 $x\neq0$ ，一次梯度下降迭代将使w变成非零值。然后就得到: $\partial y / \partial x \neq0$ 。这样就能让zero convolution模块逐渐成为具有非零权重的公共卷积层，并不断优化参数权重。

+ **ControlNet 为什么要在trainable copy前后两部分都加入zero convolution呢？**

  （来自QwQ-32B回答）两层零卷积，分别位于可训练副本网络的输入端和输出端。

  + 输入端的特征转换 ：在控制条件输入 ControlNet 时，通过 zero convolution 将输入特征映射到与主干网络特征空间兼容的维度。由于初始权重为零，这一层在训练初期几乎不改变输入，但随着训练进行，权重会逐渐调整以更好地对齐控制条件与主干网络的特征。 

  + 输出端的渐进融合 ：在 ControlNet 的输出阶段，通过另一层 zero convolution 将控制分支的特征与主干网络的特征融合。这层的作用是逐步调整控制信号的强度，确保叠加后的特征既包含控制信息，又不会破坏主干网络原有的特征结构。

+ **ControlNet在 DiT领域如何工作呢？**

  列举了一些文章/仓库：

  1. [RelaCtrl: Relevance-Guided Efficient Control for Diffusion Transformers](https://arxiv.org/pdf/2502.14377)

     <img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250329222704647.png" alt="image-20250329222704647" style="zoom: 50%;" />

  2. [Hunyuan-DiT, 腾讯混元](https://github.com/Tencent/HunyuanDiT/tree/main/controlnet)

+ **训练显存和时间变化**：

  在单个Nvidia A100 PCIE 40G的环境下，实际应用到Stable Diffusion模型的训练中，ControlNet仅使得每次迭代所需的GPU显存增加大约23%，时间增加34%左右。

------------

## Min-SNR Weighting Strategy

### 1. 从ϵ-prediction到v-prediction

1. 区别：

   + ϵ-prediction：噪声预测型，直接预测在每个时间步添加的噪声
   + v-prediciton：速度预测型，重点在于预测数据如何在时间序列中演变；

2. 重新审视加躁模型：

   + **从加噪的过程看**：干净图像和高斯噪声的权重平方是 $\bar{\alpha_t}+(1−\bar{\alpha_t})= 1$，那么就可以用**单位向量画圆**来理解干净图像和高斯噪声的关系：y轴就是干净图像，x轴是高斯噪声，z就是xt，即：从干净图像开始，以一定的步长，混合一定比例的高斯噪声，沿着圆的弧线变化，直到最后完全变成高斯噪声。

     <img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250413231219567.png" alt="image-20250413231219567" style="zoom: 25%;" />

     此时损失函数为：
     $$
     L_\theta = \left\| \epsilon - \epsilon_{\theta} \left( \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon, t \right) \right\|^2
     $$
     信噪比为：
     $$
     \text{SNR}_{ddpm} = \frac{\| x_{signal} \|^2}{\| x_{noise} \|^2} = \frac{\overline{\alpha_t}}{1-\overline{\alpha_t}}
     $$

   + **扩展到速度预测模型**：令沿着弧线的这个切向速度（可以分解为增加的噪声分量和减少的信号分量）为向量 $v_t$ ，有：
     $$
     \left\{
             \begin{array}{l}
                 v_t = \frac{dx_t}{d\phi} = \frac{d\cos\phi}{d\phi}x_0 + \frac{d\sin\phi}{d\phi}\epsilon = \sqrt{\bar{\alpha}_t}\epsilon - \sqrt{1-\bar{\alpha}_t}x_0 \\
                 x_t = \sqrt{\bar{\alpha}_t}x_0 + \sqrt{1-\bar{\alpha}_t}\epsilon
             \end{array}
         \right.
     $$
     可以通过二元一次方程求解得到：
     $$
     x_0 = \sqrt{\bar{\alpha}_t}x_t - \sqrt{1-\bar{\alpha}_t}\ v_t
     $$
     此时损失函数为：
     $$
     \begin{aligned}
     L_\theta &= \| v - v_\theta(x_t, t) \|^2 \\
     &=  \frac{1}{1-\bar{\alpha_t}}\left\| (x_0 - x_\theta(x_t, t)) \right\|^2 \\
     &=  (\text{SNR}_{ddpm} + 1)\left\|(x_0 - x_\theta(x_t, t)) \right\|^2
     \end{aligned}
     $$

   + **结论**：v-prediction 学习的是噪声变化的速度，其 loss weight 刚好比ϵ-prediction（DDPM）的SNR多一个1，缓解了在去噪前期的信号弱问题，训练相对稳定一些。

3. 参考论文：Progressive distillation for fast sampling of diffusion models

### 2. 关键点分析

通过实验证明，扩散模型收敛速度慢的原因为**训练过程中不同时间步的优化方向相互冲突，不同噪声水平下的最优权重梯度是相互冲突的。**

<img src="%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E6%8F%90%E9%AB%98%E7%9F%A5%E8%AF%86.assets/image-20250413233838523.png" alt="image-20250413233838523" style="zoom: 67%;" />

针对这一问题，提出了**Min - SNR - γ**损失加权策略。该策略将每个时间步的去噪过程视为单独的任务，从而扩散训练可以被认为是一个多任务学习问题，并通过难易程度为其分配损失权重。

**Min - SNR - γ**损失加权策略：与耗时的帕累托优化相比，是次优策略，但是更加简洁且不耗时。论文设置一个超参数 γ（默认是5），对于比较简单的case（t比较小），权重最大为5，迫使网络不要关注简单case；而对于比较难的case，权重保持不变，以此让网络关注难样本。
$$
L_{\theta} = \left\| \min(\text{SNR}+1, \gamma) (x_0 - x_\theta(x_t, t)) \right\|^2
$$


---------------

## Flow Matching

